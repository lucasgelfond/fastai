{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1472453,"sourceType":"datasetVersion","datasetId":863934}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This was default Kaggle setup/support code \n\nimport numpy as np \nimport pandas as pd \n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-25T18:53:55.507735Z","iopub.execute_input":"2024-07-25T18:53:55.508147Z","iopub.status.idle":"2024-07-25T18:53:56.633775Z","shell.execute_reply.started":"2024-07-25T18:53:55.508114Z","shell.execute_reply":"2024-07-25T18:53:56.632441Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/covid-19-nlp-text-classification/Corona_NLP_test.csv\n/kaggle/input/covid-19-nlp-text-classification/Corona_NLP_train.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# from fast.ai NLP beginners notebook, deal with path\ncreds = ''\nfrom pathlib import Path\n\ncred_path = Path('~/.kaggle/kaggle.json').expanduser()\nif not cred_path.exists():\n    cred_path.parent.mkdir(exist_ok=True)\n    cred_path.write_text(creds)\n    cred_path.chmod(0o600)","metadata":{"execution":{"iopub.status.busy":"2024-07-25T18:53:56.635944Z","iopub.execute_input":"2024-07-25T18:53:56.637003Z","iopub.status.idle":"2024-07-25T18:53:56.644505Z","shell.execute_reply.started":"2024-07-25T18:53:56.636963Z","shell.execute_reply":"2024-07-25T18:53:56.642928Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os\niskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')","metadata":{"execution":{"iopub.status.busy":"2024-07-25T18:53:56.645921Z","iopub.execute_input":"2024-07-25T18:53:56.646409Z","iopub.status.idle":"2024-07-25T18:53:56.654495Z","shell.execute_reply.started":"2024-07-25T18:53:56.646365Z","shell.execute_reply":"2024-07-25T18:53:56.653396Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# bring in NLP dataset\nif iskaggle:\n    path = Path('../input/covid-19-nlp-text-classification')\n    ! pip install -q datasets","metadata":{"execution":{"iopub.status.busy":"2024-07-25T18:53:56.657562Z","iopub.execute_input":"2024-07-25T18:53:56.657950Z","iopub.status.idle":"2024-07-25T18:54:11.982020Z","shell.execute_reply.started":"2024-07-25T18:53:56.657917Z","shell.execute_reply":"2024-07-25T18:54:11.980736Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# test to make sure we have correct files - we do! \n!ls {path}","metadata":{"execution":{"iopub.status.busy":"2024-07-25T18:54:11.983584Z","iopub.execute_input":"2024-07-25T18:54:11.983918Z","iopub.status.idle":"2024-07-25T18:54:13.104057Z","shell.execute_reply.started":"2024-07-25T18:54:11.983887Z","shell.execute_reply":"2024-07-25T18:54:13.103047Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Corona_NLP_test.csv  Corona_NLP_train.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n# note - had to swap encoding, was getting \"invalid continuation byte\" error before\n# see https://stackoverflow.com/questions/5552555/unicodedecodeerror-invalid-continuation-byte\ndf = pd.read_csv(path/'Corona_NLP_train.csv', encoding='latin-1')\n# inspect file as dataframe\ndf ","metadata":{"execution":{"iopub.status.busy":"2024-07-25T18:54:13.106029Z","iopub.execute_input":"2024-07-25T18:54:13.106504Z","iopub.status.idle":"2024-07-25T18:54:13.448005Z","shell.execute_reply.started":"2024-07-25T18:54:13.106463Z","shell.execute_reply":"2024-07-25T18:54:13.446938Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"       UserName  ScreenName                      Location     TweetAt  \\\n0          3799       48751                        London  16-03-2020   \n1          3800       48752                            UK  16-03-2020   \n2          3801       48753                     Vagabonds  16-03-2020   \n3          3802       48754                           NaN  16-03-2020   \n4          3803       48755                           NaN  16-03-2020   \n...         ...         ...                           ...         ...   \n41152     44951       89903  Wellington City, New Zealand  14-04-2020   \n41153     44952       89904                           NaN  14-04-2020   \n41154     44953       89905                           NaN  14-04-2020   \n41155     44954       89906                           NaN  14-04-2020   \n41156     44955       89907  i love you so much || he/him  14-04-2020   \n\n                                           OriginalTweet           Sentiment  \n0      @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n1      advice Talk to your neighbours family to excha...            Positive  \n2      Coronavirus Australia: Woolworths to give elde...            Positive  \n3      My food stock is not the only one which is emp...            Positive  \n4      Me, ready to go at supermarket during the #COV...  Extremely Negative  \n...                                                  ...                 ...  \n41152  Airline pilots offering to stock supermarket s...             Neutral  \n41153  Response to complaint not provided citing COVI...  Extremely Negative  \n41154  You know itÃ‚Â’s getting tough when @KameronWild...            Positive  \n41155  Is it wrong that the smell of hand sanitizer i...             Neutral  \n41156  @TartiiCat Well new/used Rift S are going for ...            Negative  \n\n[41157 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UserName</th>\n      <th>ScreenName</th>\n      <th>Location</th>\n      <th>TweetAt</th>\n      <th>OriginalTweet</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3799</td>\n      <td>48751</td>\n      <td>London</td>\n      <td>16-03-2020</td>\n      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3800</td>\n      <td>48752</td>\n      <td>UK</td>\n      <td>16-03-2020</td>\n      <td>advice Talk to your neighbours family to excha...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3801</td>\n      <td>48753</td>\n      <td>Vagabonds</td>\n      <td>16-03-2020</td>\n      <td>Coronavirus Australia: Woolworths to give elde...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3802</td>\n      <td>48754</td>\n      <td>NaN</td>\n      <td>16-03-2020</td>\n      <td>My food stock is not the only one which is emp...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3803</td>\n      <td>48755</td>\n      <td>NaN</td>\n      <td>16-03-2020</td>\n      <td>Me, ready to go at supermarket during the #COV...</td>\n      <td>Extremely Negative</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>41152</th>\n      <td>44951</td>\n      <td>89903</td>\n      <td>Wellington City, New Zealand</td>\n      <td>14-04-2020</td>\n      <td>Airline pilots offering to stock supermarket s...</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>41153</th>\n      <td>44952</td>\n      <td>89904</td>\n      <td>NaN</td>\n      <td>14-04-2020</td>\n      <td>Response to complaint not provided citing COVI...</td>\n      <td>Extremely Negative</td>\n    </tr>\n    <tr>\n      <th>41154</th>\n      <td>44953</td>\n      <td>89905</td>\n      <td>NaN</td>\n      <td>14-04-2020</td>\n      <td>You know itÃ‚Â’s getting tough when @KameronWild...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>41155</th>\n      <td>44954</td>\n      <td>89906</td>\n      <td>NaN</td>\n      <td>14-04-2020</td>\n      <td>Is it wrong that the smell of hand sanitizer i...</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>41156</th>\n      <td>44955</td>\n      <td>89907</td>\n      <td>i love you so much || he/him</td>\n      <td>14-04-2020</td>\n      <td>@TartiiCat Well new/used Rift S are going for ...</td>\n      <td>Negative</td>\n    </tr>\n  </tbody>\n</table>\n<p>41157 rows Ã— 6 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.describe(include='object')","metadata":{"execution":{"iopub.status.busy":"2024-07-25T18:54:13.449322Z","iopub.execute_input":"2024-07-25T18:54:13.449607Z","iopub.status.idle":"2024-07-25T18:54:13.549632Z","shell.execute_reply.started":"2024-07-25T18:54:13.449582Z","shell.execute_reply":"2024-07-25T18:54:13.548460Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"       Location     TweetAt  \\\ncount     32567       41157   \nunique    12220          30   \ntop      London  20-03-2020   \nfreq        540        3448   \n\n                                            OriginalTweet Sentiment  \ncount                                               41157     41157  \nunique                                              41157         5  \ntop     @TartiiCat Well new/used Rift S are going for ...  Positive  \nfreq                                                    1     11422  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Location</th>\n      <th>TweetAt</th>\n      <th>OriginalTweet</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>32567</td>\n      <td>41157</td>\n      <td>41157</td>\n      <td>41157</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>12220</td>\n      <td>30</td>\n      <td>41157</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>London</td>\n      <td>20-03-2020</td>\n      <td>@TartiiCat Well new/used Rift S are going for ...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>540</td>\n      <td>3448</td>\n      <td>1</td>\n      <td>11422</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# input - i'll use just original tweet, could do other stuff - don't want to deal w/ cleaning location data\ndf['input'] = 'OriginalTweet:' + df.OriginalTweet","metadata":{"execution":{"iopub.status.busy":"2024-07-25T18:54:13.550789Z","iopub.execute_input":"2024-07-25T18:54:13.551112Z","iopub.status.idle":"2024-07-25T18:54:13.569822Z","shell.execute_reply.started":"2024-07-25T18:54:13.551085Z","shell.execute_reply":"2024-07-25T18:54:13.568599Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# inspect to make sure this works\ndf.input.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-25T18:54:13.571141Z","iopub.execute_input":"2024-07-25T18:54:13.571462Z","iopub.status.idle":"2024-07-25T18:54:13.582225Z","shell.execute_reply.started":"2024-07-25T18:54:13.571435Z","shell.execute_reply":"2024-07-25T18:54:13.581032Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"0    OriginalTweet:@MeNyrbie @Phil_Gahan @Chrisitv ...\n1    OriginalTweet:advice Talk to your neighbours f...\n2    OriginalTweet:Coronavirus Australia: Woolworth...\n3    OriginalTweet:My food stock is not the only on...\n4    OriginalTweet:Me, ready to go at supermarket d...\nName: input, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"# create Dataset object for Transformers\nfrom datasets import Dataset,DatasetDict\nds = Dataset.from_pandas(df)\n# inspect\nds ","metadata":{"execution":{"iopub.status.busy":"2024-07-25T18:54:13.587023Z","iopub.execute_input":"2024-07-25T18:54:13.587339Z","iopub.status.idle":"2024-07-25T18:54:15.081625Z","shell.execute_reply.started":"2024-07-25T18:54:13.587313Z","shell.execute_reply":"2024-07-25T18:54:15.080641Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['UserName', 'ScreenName', 'Location', 'TweetAt', 'OriginalTweet', 'Sentiment', 'input'],\n    num_rows: 41157\n})"},"metadata":{}}]},{"cell_type":"code","source":"# just going to use deberta here, don't want to bother yet with changing model\nmodel_nm = 'microsoft/deberta-v3-small'\nfrom transformers import AutoModelForSequenceClassification,AutoTokenizer\ntokz = AutoTokenizer.from_pretrained(model_nm)","metadata":{"execution":{"iopub.status.busy":"2024-07-25T18:54:15.082967Z","iopub.execute_input":"2024-07-25T18:54:15.083540Z","iopub.status.idle":"2024-07-25T18:54:21.932973Z","shell.execute_reply.started":"2024-07-25T18:54:15.083512Z","shell.execute_reply":"2024-07-25T18:54:21.932067Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca7f7f5b862949ddb94070bb0f40ec2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/578 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6d5d49365b647179e0005ed9d069832"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a52c0e05efb348748ac6e66494e2c57f"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:562: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"tokz.tokenize(\"Here's my tokenized sentence from Deberta.\")","metadata":{"execution":{"iopub.status.busy":"2024-07-25T18:54:21.934451Z","iopub.execute_input":"2024-07-25T18:54:21.935117Z","iopub.status.idle":"2024-07-25T18:54:21.943204Z","shell.execute_reply.started":"2024-07-25T18:54:21.935078Z","shell.execute_reply":"2024-07-25T18:54:21.942219Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"['â–Here',\n \"'\",\n 's',\n 'â–my',\n 'â–token',\n 'ized',\n 'â–sentence',\n 'â–from',\n 'â–Deb',\n 'erta',\n '.']"},"metadata":{}}]},{"cell_type":"code","source":"# bring in test set \neval_df = pd.read_csv(path/'Corona_NLP_test.csv')\neval_df","metadata":{"execution":{"iopub.status.busy":"2024-07-25T18:54:21.944659Z","iopub.execute_input":"2024-07-25T18:54:21.945063Z","iopub.status.idle":"2024-07-25T18:54:21.994763Z","shell.execute_reply.started":"2024-07-25T18:54:21.945029Z","shell.execute_reply":"2024-07-25T18:54:21.993637Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"      UserName  ScreenName             Location     TweetAt  \\\n0            1       44953                  NYC  02-03-2020   \n1            2       44954          Seattle, WA  02-03-2020   \n2            3       44955                  NaN  02-03-2020   \n3            4       44956          Chicagoland  02-03-2020   \n4            5       44957  Melbourne, Victoria  03-03-2020   \n...        ...         ...                  ...         ...   \n3793      3794       48746            Israel ??  16-03-2020   \n3794      3795       48747       Farmington, NM  16-03-2020   \n3795      3796       48748        Haverford, PA  16-03-2020   \n3796      3797       48749                  NaN  16-03-2020   \n3797      3798       48750  Arlington, Virginia  16-03-2020   \n\n                                          OriginalTweet           Sentiment  \n0     TRENDING: New Yorkers encounter empty supermar...  Extremely Negative  \n1     When I couldn't find hand sanitizer at Fred Me...            Positive  \n2     Find out how you can protect yourself and love...  Extremely Positive  \n3     #Panic buying hits #NewYork City as anxious sh...            Negative  \n4     #toiletpaper #dunnypaper #coronavirus #coronav...             Neutral  \n...                                                 ...                 ...  \n3793  Meanwhile In A Supermarket in Israel -- People...            Positive  \n3794  Did you panic buy a lot of non-perishable item...            Negative  \n3795  Asst Prof of Economics @cconces was on @NBCPhi...             Neutral  \n3796  Gov need to do somethings instead of biar je r...  Extremely Negative  \n3797  I and @ForestandPaper members are committed to...  Extremely Positive  \n\n[3798 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UserName</th>\n      <th>ScreenName</th>\n      <th>Location</th>\n      <th>TweetAt</th>\n      <th>OriginalTweet</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>44953</td>\n      <td>NYC</td>\n      <td>02-03-2020</td>\n      <td>TRENDING: New Yorkers encounter empty supermar...</td>\n      <td>Extremely Negative</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>44954</td>\n      <td>Seattle, WA</td>\n      <td>02-03-2020</td>\n      <td>When I couldn't find hand sanitizer at Fred Me...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>44955</td>\n      <td>NaN</td>\n      <td>02-03-2020</td>\n      <td>Find out how you can protect yourself and love...</td>\n      <td>Extremely Positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>44956</td>\n      <td>Chicagoland</td>\n      <td>02-03-2020</td>\n      <td>#Panic buying hits #NewYork City as anxious sh...</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>44957</td>\n      <td>Melbourne, Victoria</td>\n      <td>03-03-2020</td>\n      <td>#toiletpaper #dunnypaper #coronavirus #coronav...</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3793</th>\n      <td>3794</td>\n      <td>48746</td>\n      <td>Israel ??</td>\n      <td>16-03-2020</td>\n      <td>Meanwhile In A Supermarket in Israel -- People...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>3794</th>\n      <td>3795</td>\n      <td>48747</td>\n      <td>Farmington, NM</td>\n      <td>16-03-2020</td>\n      <td>Did you panic buy a lot of non-perishable item...</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>3795</th>\n      <td>3796</td>\n      <td>48748</td>\n      <td>Haverford, PA</td>\n      <td>16-03-2020</td>\n      <td>Asst Prof of Economics @cconces was on @NBCPhi...</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>3796</th>\n      <td>3797</td>\n      <td>48749</td>\n      <td>NaN</td>\n      <td>16-03-2020</td>\n      <td>Gov need to do somethings instead of biar je r...</td>\n      <td>Extremely Negative</td>\n    </tr>\n    <tr>\n      <th>3797</th>\n      <td>3798</td>\n      <td>48750</td>\n      <td>Arlington, Virginia</td>\n      <td>16-03-2020</td>\n      <td>I and @ForestandPaper members are committed to...</td>\n      <td>Extremely Positive</td>\n    </tr>\n  </tbody>\n</table>\n<p>3798 rows Ã— 6 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# need to set the eval_df up the same as above\neval_df['input'] = 'OriginalTweet:' + df.OriginalTweet","metadata":{"execution":{"iopub.status.busy":"2024-07-25T18:54:21.996112Z","iopub.execute_input":"2024-07-25T18:54:21.996524Z","iopub.status.idle":"2024-07-25T18:54:22.015684Z","shell.execute_reply.started":"2024-07-25T18:54:21.996494Z","shell.execute_reply":"2024-07-25T18:54:22.014631Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# when I attempt to train, getting the issue that I fail to truncate \n# need to get the max length in both the evaluation and train dfs\n# first create input_length col in both\ndf['input_length'] = df['input'].apply(len)\neval_df['input_length'] = eval_df['input'].apply(len)\n\n# next get maximums\nmax_input_len_train = df['input_length'].max()\nmax_input_len_eval = df['input_length'].max()\n\nmax_length = max_input_len_train\nif max_input_len_eval > max_input_len_train:\n    max_length = max_input_len_eval\n\nmax_length","metadata":{"execution":{"iopub.status.busy":"2024-07-25T18:54:22.017080Z","iopub.execute_input":"2024-07-25T18:54:22.017515Z","iopub.status.idle":"2024-07-25T18:54:22.063935Z","shell.execute_reply.started":"2024-07-25T18:54:22.017477Z","shell.execute_reply":"2024-07-25T18:54:22.062754Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"369"},"metadata":{}}]},{"cell_type":"code","source":"# tokenize all of our inputs\n# NOTE: initially got a problem when this had NoneTypes from Location;\n# if this was more serious I'd clean the data to get rid of this, but location seems lossy anyways \ndef tok_func(x): return tokz(x[\"input\"], padding=True, truncation=True, max_length=max_length)\ntok_ds = ds.map(tok_func, batched=True)\n# DataSet from DataFrame, tokenized\neval_ds = Dataset.from_pandas(eval_df).map(tok_func, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-25T18:54:22.065272Z","iopub.execute_input":"2024-07-25T18:54:22.065724Z","iopub.status.idle":"2024-07-25T18:54:32.024673Z","shell.execute_reply.started":"2024-07-25T18:54:22.065682Z","shell.execute_reply":"2024-07-25T18:54:32.023752Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/41157 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdbd90d4049146de8e08a708142b50e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3798 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e8f165a4f1d4cd88e3b60b072e02f34"}},"metadata":{}}]},{"cell_type":"code","source":"# transformers assumes labelshas column \"labels\"\ntok_ds = tok_ds.rename_columns({'Sentiment':'labels'})\neval_ds = eval_ds.rename_columns({'Sentiment':'labels'})","metadata":{"execution":{"iopub.status.busy":"2024-07-25T18:54:32.026059Z","iopub.execute_input":"2024-07-25T18:54:32.027080Z","iopub.status.idle":"2024-07-25T18:54:32.036829Z","shell.execute_reply.started":"2024-07-25T18:54:32.027048Z","shell.execute_reply":"2024-07-25T18:54:32.035945Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# however, we don't want to use the eval_df as our validation set, just our eventual test set\n# going to make a validation set here:\ndds = tok_ds.train_test_split(0.25, seed=42)\ndds","metadata":{"execution":{"iopub.status.busy":"2024-07-25T18:54:32.038077Z","iopub.execute_input":"2024-07-25T18:54:32.038511Z","iopub.status.idle":"2024-07-25T18:54:32.081452Z","shell.execute_reply.started":"2024-07-25T18:54:32.038474Z","shell.execute_reply":"2024-07-25T18:54:32.080512Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['UserName', 'ScreenName', 'Location', 'TweetAt', 'OriginalTweet', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 30867\n    })\n    test: Dataset({\n        features: ['UserName', 'ScreenName', 'Location', 'TweetAt', 'OriginalTweet', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 10290\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import TrainingArguments,Trainer\n","metadata":{"execution":{"iopub.status.busy":"2024-07-25T18:54:32.089582Z","iopub.execute_input":"2024-07-25T18:54:32.089912Z","iopub.status.idle":"2024-07-25T18:54:45.018246Z","shell.execute_reply.started":"2024-07-25T18:54:32.089888Z","shell.execute_reply":"2024-07-25T18:54:45.017103Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"2024-07-25 18:54:34.063094: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-25 18:54:34.063241: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-25 18:54:34.180295: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# the specifics here are fuzzy to me but as I understand it\n# the Pearson coefficient shows how much two things are correlated\n# here we are going to find correlation between our predictions and the ground truth of the eval est\ndef corr(x,y): return np.corrcoef(x,y)[0][1]\ndef corr_d(eval_pred): return {'pearson': corr(*eval_pred)}","metadata":{"execution":{"iopub.status.busy":"2024-07-25T18:54:45.155915Z","iopub.execute_input":"2024-07-25T18:54:45.157011Z","iopub.status.idle":"2024-07-25T18:54:45.163301Z","shell.execute_reply.started":"2024-07-25T18:54:45.156962Z","shell.execute_reply":"2024-07-25T18:54:45.162252Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# look at current format - these are correctly tokenized - for debugging \n# dds['train']['input_ids'][0]","metadata":{"execution":{"iopub.status.busy":"2024-07-25T18:54:45.165291Z","iopub.execute_input":"2024-07-25T18:54:45.166022Z","iopub.status.idle":"2024-07-25T18:54:45.173918Z","shell.execute_reply.started":"2024-07-25T18:54:45.165983Z","shell.execute_reply":"2024-07-25T18:54:45.172375Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# need to get the unique labels into numbers\nunique_labels = list(set(tok_ds['labels']))\nunique_labels\n","metadata":{"execution":{"iopub.status.busy":"2024-07-25T18:54:45.175896Z","iopub.execute_input":"2024-07-25T18:54:45.177604Z","iopub.status.idle":"2024-07-25T18:54:45.258547Z","shell.execute_reply.started":"2024-07-25T18:54:45.177561Z","shell.execute_reply":"2024-07-25T18:54:45.257264Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"['Extremely Negative', 'Positive', 'Extremely Positive', 'Negative', 'Neutral']"},"metadata":{}}]},{"cell_type":"code","source":"label_dict = {\n    'Extremely Negative': 0,\n    'Negative': 0.25,\n    'Neutral': 0.5,\n    'Positive': 0.75,\n    'Extremely Positive': 1\n}","metadata":{"execution":{"iopub.status.busy":"2024-07-25T18:54:45.260084Z","iopub.execute_input":"2024-07-25T18:54:45.260534Z","iopub.status.idle":"2024-07-25T18:54:45.267302Z","shell.execute_reply.started":"2024-07-25T18:54:45.260497Z","shell.execute_reply":"2024-07-25T18:54:45.266135Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def format_labels(examples):\n    examples['labels'] = [label_dict[label] for label in examples['labels']]\n    return examples","metadata":{"execution":{"iopub.status.busy":"2024-07-25T18:54:45.268797Z","iopub.execute_input":"2024-07-25T18:54:45.269124Z","iopub.status.idle":"2024-07-25T18:54:45.276884Z","shell.execute_reply.started":"2024-07-25T18:54:45.269097Z","shell.execute_reply":"2024-07-25T18:54:45.275835Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Apply the format_labels function to the dataset using the map method\nformatted_dds = dds.map(format_labels, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-25T18:54:45.278296Z","iopub.execute_input":"2024-07-25T18:54:45.278649Z","iopub.status.idle":"2024-07-25T18:54:52.196320Z","shell.execute_reply.started":"2024-07-25T18:54:45.278615Z","shell.execute_reply":"2024-07-25T18:54:52.195266Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/30867 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07abb09befa94e88954c43407db92164"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10290 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ed3d494e82d43e79e86b190629f8312"}},"metadata":{}}]},{"cell_type":"code","source":"formatted_dds['train'][0]['labels']","metadata":{"execution":{"iopub.status.busy":"2024-07-25T18:54:52.203031Z","iopub.execute_input":"2024-07-25T18:54:52.203460Z","iopub.status.idle":"2024-07-25T18:54:52.213397Z","shell.execute_reply.started":"2024-07-25T18:54:52.203423Z","shell.execute_reply":"2024-07-25T18:54:52.212257Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"0.75"},"metadata":{}}]},{"cell_type":"code","source":"bs = 32\nepochs = 4\nlr = 8e-5","metadata":{"execution":{"iopub.status.busy":"2024-07-25T18:57:43.998238Z","iopub.execute_input":"2024-07-25T18:57:43.999502Z","iopub.status.idle":"2024-07-25T18:57:44.004278Z","shell.execute_reply.started":"2024-07-25T18:57:43.999455Z","shell.execute_reply":"2024-07-25T18:57:44.003237Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"args = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n    evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n    num_train_epochs=epochs, weight_decay=0.01, report_to='none')","metadata":{"execution":{"iopub.status.busy":"2024-07-25T18:57:45.511200Z","iopub.execute_input":"2024-07-25T18:57:45.511613Z","iopub.status.idle":"2024-07-25T18:57:45.546755Z","shell.execute_reply.started":"2024-07-25T18:57:45.511583Z","shell.execute_reply":"2024-07-25T18:57:45.545653Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=1)\ntrainer = Trainer(model, args, train_dataset=formatted_dds['train'], eval_dataset=formatted_dds['test'],\n                  tokenizer=tokz, compute_metrics=corr_d)\ntrainer.train();","metadata":{"execution":{"iopub.status.busy":"2024-07-25T18:57:46.804513Z","iopub.execute_input":"2024-07-25T18:57:46.804904Z","iopub.status.idle":"2024-07-25T19:34:49.349354Z","shell.execute_reply.started":"2024-07-25T18:57:46.804874Z","shell.execute_reply":"2024-07-25T19:34:49.348445Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1932' max='1932' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1932/1932 37:00, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Pearson</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.027971</td>\n      <td>0.882680</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.059600</td>\n      <td>0.022763</td>\n      <td>0.922180</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.019200</td>\n      <td>0.014756</td>\n      <td>0.936465</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.009500</td>\n      <td>0.013716</td>\n      <td>0.942082</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"}]},{"cell_type":"code","source":"eval_ds = Dataset.from_pandas(eval_df).map(tok_func, batched=True)\npreds = trainer.predict(eval_ds).predictions.astype(float)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-25T19:41:38.464673Z","iopub.execute_input":"2024-07-25T19:41:38.465099Z","iopub.status.idle":"2024-07-25T19:41:54.699079Z","shell.execute_reply.started":"2024-07-25T19:41:38.465064Z","shell.execute_reply":"2024-07-25T19:41:54.697950Z"},"trusted":true},"execution_count":46,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3798 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7854d81f809e437cbcde16cb8e1a7ffb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"array([[0.50294423],\n       [0.73556268],\n       [0.77110201],\n       ...,\n       [0.25231057],\n       [0.78408509],\n       [0.89477992]])"},"metadata":{}}]},{"cell_type":"code","source":"evaluation_results = trainer.evaluate()\nevaluation_results","metadata":{"execution":{"iopub.status.busy":"2024-07-25T19:45:32.994836Z","iopub.execute_input":"2024-07-25T19:45:32.995358Z","iopub.status.idle":"2024-07-25T19:46:31.853691Z","shell.execute_reply.started":"2024-07-25T19:45:32.995315Z","shell.execute_reply":"2024-07-25T19:46:31.852222Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.013715675100684166,\n 'eval_pearson': 0.9420822092639983,\n 'eval_runtime': 58.8447,\n 'eval_samples_per_second': 174.867,\n 'eval_steps_per_second': 1.377,\n 'epoch': 4.0}"},"metadata":{}}]}]}