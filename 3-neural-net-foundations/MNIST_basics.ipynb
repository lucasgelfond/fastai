{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvTy401Gt1BB",
        "outputId": "f094a2b3-1216-47e2-a391-23577c8858cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.8/719.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mMounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#hide\n",
        "! [ -e /content ] && pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#hide\n",
        "from fastai.vision.all import *\n",
        "from fastbook import *\n",
        "\n",
        "matplotlib.rc('image', cmap='Greys')"
      ],
      "metadata": {
        "id": "r33fQLn5t6ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST_SAMPLE doesn't have 2s / 4s\n",
        "path = untar_data(URLs.MNIST)"
      ],
      "metadata": {
        "id": "drTjpa7Yt7g3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "3ad23ad8-354b-4caf-d394-03a00cdaac7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='15687680' class='' max='15683414' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.03% [15687680/15683414 00:00&lt;00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path.ls() # note - \"testing\" and \"training\" vs. \"train\" and \"test\""
      ],
      "metadata": {
        "id": "tDxgtYFiuu9T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aec6b27-d578-43cb-d858-62866f1386c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [Path('/root/.fastai/data/mnist_png/training'),Path('/root/.fastai/data/mnist_png/testing')]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#hide\n",
        "Path.BASE_PATH = path"
      ],
      "metadata": {
        "id": "7FryyKAbt-xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fours = (path/'training'/'4').ls().sorted()\n",
        "twos = (path/'training'/'2').ls().sorted()"
      ],
      "metadata": {
        "id": "i1n5UzhQuAYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create validation set\n",
        "valid_2_tens = torch.stack([tensor(Image.open(o)) for o in (path/'testing'/'2').ls()])\n",
        "valid_2_tens = valid_2_tens.float()/255\n",
        "\n",
        "valid_4_tens = torch.stack([tensor(Image.open(o)) for o in (path/'testing'/'4').ls()])\n",
        "valid_4_tens = valid_4_tens.float()/255"
      ],
      "metadata": {
        "id": "jp2W_MSSuH4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare two and four training sets for training\n",
        "two_tensors = [tensor(Image.open(o)) for o in twos]\n",
        "four_tensors = [tensor(Image.open(o)) for o in fours]\n",
        "stacked_twos = torch.stack(two_tensors).float()/255\n",
        "stacked_fours = torch.stack(four_tensors).float()/255"
      ],
      "metadata": {
        "id": "c7LalrffwYlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "lr = 1e-6"
      ],
      "metadata": {
        "id": "SlpK9_eAvZXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# all of the labels of twos, then all of the fours - 1 if a two, 0 if a four\n",
        "train_x = torch.cat([stacked_twos, stacked_fours]).view(-1, 28*28)\n",
        "train_y = tensor([1]*len(stacked_twos) + [0]*len(stacked_fours)).unsqueeze(1)\n",
        "\n",
        "dset = list(zip(train_x, train_y))"
      ],
      "metadata": {
        "id": "1qWJZYC3v5Iq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_x = torch.cat([valid_2_tens, valid_4_tens]).view(-1, 28*28)\n",
        "valid_y = tensor([1]*len(valid_2_tens) + [0]*len(valid_4_tens)).unsqueeze(1)\n",
        "valid_dset = list(zip(valid_x, valid_y))"
      ],
      "metadata": {
        "id": "NTksWKLqxB-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_params(size, std=1.0):\n",
        "  return (torch.randn(size)*std).requires_grad_()"
      ],
      "metadata": {
        "id": "yhd9BRwtxJkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = init_params((28*28, 1))\n",
        "bias = init_params(1)"
      ],
      "metadata": {
        "id": "W15A1vkwxQ1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def linear1(xb): return xb@weights + bias"
      ],
      "metadata": {
        "id": "EMSt4lCRxala"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mnist_loss(predictions, targets):\n",
        "    predictions = predictions.sigmoid()\n",
        "    return torch.where(targets==1, 1-predictions, predictions).mean()"
      ],
      "metadata": {
        "id": "DpnOtF1SxuZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dl = DataLoader(dset, batch_size=256)\n",
        "valid_dl = DataLoader(valid_dset, batch_size=256)"
      ],
      "metadata": {
        "id": "wI_q9xEjyo6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# minibatch for testing\n",
        "batch = train_x[:4]\n",
        "batch.shape"
      ],
      "metadata": {
        "id": "20I9r-_Dy7aS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d104542a-0f8b-4509-ba41-87e9ec7b0dd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 784])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_grad(xb, yb, model):\n",
        "    # zero out gradients first\n",
        "    weights.grad.zero_()\n",
        "    bias.grad.zero_();\n",
        "    preds = model(xb)\n",
        "    loss = mnist_loss(preds, yb)\n",
        "    loss.backward()"
      ],
      "metadata": {
        "id": "8OTSP_jJzHPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, lr, params):\n",
        "    for xb, yb in dl:\n",
        "        calc_grad(xb, yb, model)\n",
        "        for p in params:\n",
        "            p.data -= p.grad * lr\n",
        "            p.grad.zero_()"
      ],
      "metadata": {
        "id": "lAGIBtYhzet5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_accuracy(xb, yb):\n",
        "    preds = xb.sigmoid()\n",
        "    correct = (preds>0.5) == yb\n",
        "    return correct.float().mean()"
      ],
      "metadata": {
        "id": "qFIRDBUHzg7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_epoch(model):\n",
        "    accs = [batch_accuracy(model(xb), yb) for xb,yb in valid_dl]\n",
        "    return round(torch.stack(accs).mean().item(), 4)"
      ],
      "metadata": {
        "id": "t3aDWfExzihZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = weights, bias\n",
        "lr = 5e-4\n",
        "for i in range(200):\n",
        "    train_epoch(linear1, lr, params)\n",
        "    print(validate_epoch(linear1), end=' ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3ODYIdrzlak",
        "outputId": "fd0b67de-bcfa-441a-b933-85fa1ab56fa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6134 0.6139 0.6139 0.6139 0.6143 0.6152 0.6162 0.6162 0.6162 0.6162 0.6161 0.6161 0.6161 0.6176 0.6176 0.6176 0.6186 0.6186 0.6191 0.62 0.621 0.622 0.6225 0.6235 0.6235 0.623 0.623 0.6235 0.624 0.6249 0.6259 0.6264 0.6264 0.6269 0.6264 0.6264 0.6269 0.6269 0.6269 0.6279 0.6288 0.6298 0.6298 0.6298 0.6303 0.6303 0.6308 0.6308 0.6308 0.6308 0.6313 0.6308 0.6313 0.6318 0.6312 0.6312 0.6317 0.6317 0.6322 0.6327 0.6322 0.6322 0.6322 0.6327 0.6327 0.6327 0.6332 0.6337 0.6342 0.6342 0.6347 0.6351 0.6351 0.6361 0.6366 0.6366 0.6371 0.6376 0.6381 0.64 0.64 0.64 0.64 0.64 0.64 0.6396 0.6396 0.6396 0.6396 0.6396 0.6396 0.6396 0.6415 0.642 0.643 0.643 0.644 0.6444 0.6444 0.6444 0.6449 0.6449 0.6455 0.6455 0.6474 0.6479 0.6489 0.6499 0.6508 0.6508 0.6518 0.6523 0.6528 0.6528 0.6528 0.6528 0.6528 0.6528 0.6533 0.6538 0.6547 0.6552 0.6557 0.6557 0.6557 0.6557 0.6567 0.6567 0.6572 0.6577 0.6577 0.6571 0.6581 0.6581 0.6595 0.66 0.6605 0.661 0.6615 0.6615 0.662 0.6639 0.6639 0.6644 0.6644 0.6649 0.6649 0.6649 0.6644 0.6644 0.6649 0.6654 0.6654 0.6659 0.6659 0.6664 0.6669 0.6669 0.6674 0.6683 0.6683 0.6698 0.6698 0.6708 0.6708 0.6708 0.6708 0.6708 0.6713 0.6713 0.6713 0.6717 0.6717 0.6717 0.6722 0.6722 0.6727 0.6727 0.6736 0.6736 0.6736 0.6736 0.6736 0.6741 0.6751 0.6751 0.6751 0.6751 0.6756 0.6766 0.6766 0.6766 0.677 0.677 0.6775 0.6775 0.6775 0.6775 0.678 0.679 "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below here we're swapping our functionality out for how it is done correctly in PyTorch. Here I'm doing it less minimally."
      ],
      "metadata": {
        "id": "NScRKC2dFpKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model = nn.Linear(28*28, 1)\n",
        "w,b = linear_model.parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBB5hCVvDevp",
        "outputId": "f66b325b-a12a-4fbd-84c7-0a321080de42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 784]), torch.Size([1]))"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicOptim:\n",
        "    def __init__(self,params,lr): self.params,self.lr = list(params),lr\n",
        "\n",
        "    def step(self, *args, **kwargs):\n",
        "        for p in self.params: p.data -= p.grad.data * self.lr\n",
        "\n",
        "    def zero_grad(self, *args, **kwargs):\n",
        "        for p in self.params: p.grad = None"
      ],
      "metadata": {
        "id": "JHfkzInYDlvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = BasicOptim(linear_model.parameters(), lr)"
      ],
      "metadata": {
        "id": "aERKk74LDqWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model):\n",
        "    for xb,yb in dl:\n",
        "        calc_grad(xb, yb, model)\n",
        "        opt.step()\n",
        "        opt.zero_grad()"
      ],
      "metadata": {
        "id": "eLGueXW7Dr4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validate_epoch(linear_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16CqeFNnDvQX",
        "outputId": "9e4e4826-6ffa-42b6-b0fc-e54215a98bc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3013"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, epochs):\n",
        "    for i in range(epochs):\n",
        "        train_epoch(model)\n",
        "        print(validate_epoch(model), end=' ')"
      ],
      "metadata": {
        "id": "8VwE7So8Dwef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(linear_model, 20)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvD3bgHsDzZO",
        "outputId": "ef27411d-439f-48e5-efe9-4ac91f0e2661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3789 0.4734 0.5744 0.6578 0.7414 0.8051 0.8453 0.8708 0.8959 0.9118 0.9227 0.9323 0.9417 0.9446 0.9465 0.9489 0.9514 0.9538 0.9568 0.9595 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "linear_model = nn.Linear(28*28,1)\n",
        "opt = SGD(linear_model.parameters(), lr)\n",
        "train_model(linear_model, 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qfewNwnD72q",
        "outputId": "365bcf2f-d6e6-4d84-a598-3132404a68a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.597 0.6791 0.7533 0.8065 0.8454 0.8707 0.8873 0.902 0.914 0.9227 0.9281 0.9324 0.9372 0.9388 0.9423 0.9453 0.9478 0.9492 0.9507 0.9512 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dls = DataLoaders(dl, valid_dl)\n"
      ],
      "metadata": {
        "id": "frL5_U1hEB-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "learn = Learner(dls, nn.Linear(28*28,1), opt_func=SGD,\n",
        "                loss_func=mnist_loss, metrics=batch_accuracy)"
      ],
      "metadata": {
        "id": "wozrfpixECdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn.fit(10, lr=lr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "Biniu85oEEGh",
        "outputId": "ffde2456-5f39-4084-e813-323ec9f5d3c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>batch_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.507328</td>\n",
              "      <td>0.507725</td>\n",
              "      <td>0.443893</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.502179</td>\n",
              "      <td>0.499544</td>\n",
              "      <td>0.513623</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.496231</td>\n",
              "      <td>0.491343</td>\n",
              "      <td>0.594774</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.489750</td>\n",
              "      <td>0.483142</td>\n",
              "      <td>0.669098</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.482957</td>\n",
              "      <td>0.474960</td>\n",
              "      <td>0.737525</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.476005</td>\n",
              "      <td>0.466818</td>\n",
              "      <td>0.792111</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.468991</td>\n",
              "      <td>0.458736</td>\n",
              "      <td>0.834192</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.461967</td>\n",
              "      <td>0.450730</td>\n",
              "      <td>0.864852</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.454967</td>\n",
              "      <td>0.442818</td>\n",
              "      <td>0.890144</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.448010</td>\n",
              "      <td>0.435016</td>\n",
              "      <td>0.902030</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "simple_net = nn.Sequential(\n",
        "    nn.Linear(28*28,30),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(30,1)\n",
        ")"
      ],
      "metadata": {
        "id": "y1tNxORtEOe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "learn = Learner(dls, simple_net, opt_func=SGD,\n",
        "                loss_func=mnist_loss, metrics=batch_accuracy)"
      ],
      "metadata": {
        "id": "1__jdU_DEQ8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn.fit(40, 0.1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jjNBIK5dEVEu",
        "outputId": "e3771845-867e-4979-b6bf-f012efa9225c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>batch_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.330891</td>\n",
              "      <td>0.440409</td>\n",
              "      <td>0.490070</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.171102</td>\n",
              "      <td>0.270927</td>\n",
              "      <td>0.738456</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.097241</td>\n",
              "      <td>0.133704</td>\n",
              "      <td>0.900912</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.064138</td>\n",
              "      <td>0.085564</td>\n",
              "      <td>0.939176</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.048829</td>\n",
              "      <td>0.065400</td>\n",
              "      <td>0.953078</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.041163</td>\n",
              "      <td>0.055080</td>\n",
              "      <td>0.956585</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.036946</td>\n",
              "      <td>0.048976</td>\n",
              "      <td>0.960092</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.034381</td>\n",
              "      <td>0.044953</td>\n",
              "      <td>0.965554</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.032657</td>\n",
              "      <td>0.042119</td>\n",
              "      <td>0.967043</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.031398</td>\n",
              "      <td>0.040015</td>\n",
              "      <td>0.969029</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.030420</td>\n",
              "      <td>0.038392</td>\n",
              "      <td>0.970519</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.029625</td>\n",
              "      <td>0.037104</td>\n",
              "      <td>0.971046</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.028959</td>\n",
              "      <td>0.036059</td>\n",
              "      <td>0.972039</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.028387</td>\n",
              "      <td>0.035194</td>\n",
              "      <td>0.972536</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.027888</td>\n",
              "      <td>0.034467</td>\n",
              "      <td>0.972536</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.027445</td>\n",
              "      <td>0.033851</td>\n",
              "      <td>0.972039</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.027050</td>\n",
              "      <td>0.033321</td>\n",
              "      <td>0.972039</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.026693</td>\n",
              "      <td>0.032861</td>\n",
              "      <td>0.972039</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.026369</td>\n",
              "      <td>0.032457</td>\n",
              "      <td>0.972039</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.026072</td>\n",
              "      <td>0.032099</td>\n",
              "      <td>0.972039</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.025799</td>\n",
              "      <td>0.031780</td>\n",
              "      <td>0.972039</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.025546</td>\n",
              "      <td>0.031494</td>\n",
              "      <td>0.972039</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.025310</td>\n",
              "      <td>0.031234</td>\n",
              "      <td>0.972039</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.025091</td>\n",
              "      <td>0.030998</td>\n",
              "      <td>0.972039</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.024885</td>\n",
              "      <td>0.030781</td>\n",
              "      <td>0.972039</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.024692</td>\n",
              "      <td>0.030581</td>\n",
              "      <td>0.970612</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.024510</td>\n",
              "      <td>0.030395</td>\n",
              "      <td>0.971108</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.024338</td>\n",
              "      <td>0.030222</td>\n",
              "      <td>0.971108</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.024174</td>\n",
              "      <td>0.030061</td>\n",
              "      <td>0.970612</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.024020</td>\n",
              "      <td>0.029910</td>\n",
              "      <td>0.970612</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.023873</td>\n",
              "      <td>0.029769</td>\n",
              "      <td>0.970612</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.023732</td>\n",
              "      <td>0.029635</td>\n",
              "      <td>0.971108</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.023597</td>\n",
              "      <td>0.029509</td>\n",
              "      <td>0.971108</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.023469</td>\n",
              "      <td>0.029390</td>\n",
              "      <td>0.970643</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.023345</td>\n",
              "      <td>0.029277</td>\n",
              "      <td>0.970643</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.023226</td>\n",
              "      <td>0.029170</td>\n",
              "      <td>0.970643</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.023111</td>\n",
              "      <td>0.029068</td>\n",
              "      <td>0.971140</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.023001</td>\n",
              "      <td>0.028971</td>\n",
              "      <td>0.971636</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.022895</td>\n",
              "      <td>0.028879</td>\n",
              "      <td>0.972133</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.022792</td>\n",
              "      <td>0.028790</td>\n",
              "      <td>0.972629</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}